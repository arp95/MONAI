name: crons

on:
  schedule:
    - cron: "0 2 * * *"  # at 02:00 UTC

jobs:
  cron-gpu:
    container:
      image: nvcr.io/nvidia/pytorch:20.03-py3
      options: "--gpus all"
    runs-on: [self-hosted, linux, x64]
    strategy:
      matrix:
        pytorch-version: [1.4.0, 1.5.1]
    steps:
    - uses: actions/checkout@v2
    - name: Install the dependencies
      run: |
        which python
        python -m pip install --upgrade pip wheel
        python -m pip uninstall -y torch torchvision
        python -m pip install torch==${{ matrix.pytorch-version }}
        python -m pip install -r requirements-dev.txt
        python -m pip list
    - name: Run tests report coverage
      run: |
        nvidia-smi
        export CUDA_VISIBLE_DEVICES=$(python -m tests.utils)
        echo $CUDA_VISIBLE_DEVICES
        python -c "import torch; print(torch.__version__); print('{} of GPUs available'.format(torch.cuda.device_count()))"
        python -c 'import torch; print(torch.rand(5,3, device=torch.device("cuda:0")))'
        ./runtests.sh --coverage
        coverage xml
    - name: Upload coverage
      uses: codecov/codecov-action@v1
      with:
        fail_ci_if_error: false
        file: ./coverage.xml

  cron-docker:
    container:
      image: docker://projectmonai/monai:latest
      options: "--gpus all"
    runs-on: [self-hosted, linux, x64]
    steps:
    - name: Run tests report coverage
      run: |
        cd /opt/monai
        nvidia-smi
        export CUDA_VISIBLE_DEVICES=$(python -m tests.utils)
        echo $CUDA_VISIBLE_DEVICES
        python -c "import torch; print(torch.__version__); print('{} of GPUs available'.format(torch.cuda.device_count()))"
        python -c 'import torch; print(torch.rand(5,3, device=torch.device("cuda:0")))'
        ngc --version
        ./runtests.sh --coverage --codeformat
        coverage xml
    - name: Upload coverage
      uses: codecov/codecov-action@v1
      with:
        fail_ci_if_error: false
        file: ./coverage.xml
